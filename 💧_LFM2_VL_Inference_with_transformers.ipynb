{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nypstud/Awesome-Nano-Banana-images/blob/main/%F0%9F%92%A7_LFM2_VL_Inference_with_transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ’§ LFM2-VL Inference with transformers\n",
        "\n",
        "This notebook allows you to easily run LFM2-VL models (like [`LiquidAI/LFM2-VL-1.6B`](https://huggingface.co/LiquidAI/LFM2-VL-1.6B)) with Hugging Face's [transformers](https://github.com/huggingface/transformers) library.\n",
        "\n",
        "You can run it on GPU or CPU by switching the runtime (`Runtime` â†’ `Change runtime type`)."
      ],
      "metadata": {
        "id": "EszFuLYdDtuM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUEBz2_2DiAe"
      },
      "outputs": [],
      "source": [
        "!pip install -qqqU transformers pillow --progress-bar off\n",
        "\n",
        "from transformers import AutoProcessor, AutoModelForImageTextToText, TextStreamer\n",
        "from transformers.image_utils import load_image\n",
        "\n",
        "# Load model and processor\n",
        "model_id = \"LiquidAI/LFM2-VL-1.6B\"\n",
        "model = AutoModelForImageTextToText.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=\"bfloat16\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)\n",
        "streamer = TextStreamer(processor, skip_prompt=True, skip_special_tokens=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Image as IPImage\n",
        "\n",
        "# Load image\n",
        "url = \"https://www.ilankelman.org/stopsigns/australia.jpg\"\n",
        "image = load_image(url)\n",
        "display(IPImage(url=url))\n",
        "\n",
        "# Create conversation\n",
        "conversation = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\"type\": \"image\", \"image\": image},\n",
        "            {\"type\": \"text\", \"text\": \"What is in this image?\"},\n",
        "        ],\n",
        "    },\n",
        "]\n",
        "\n",
        "# Generate answer\n",
        "inputs = processor.apply_chat_template(\n",
        "    conversation,\n",
        "    add_generation_prompt=True,\n",
        "    return_tensors=\"pt\",\n",
        "    return_dict=True,\n",
        "    tokenize=True,\n",
        ").to(model.device)\n",
        "outputs = model.generate(**inputs, max_new_tokens=256, streamer=streamer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7D_VXhI6EPCq",
        "outputId": "678773fe-7e79-46db-ef1d-2e6e862947f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://www.ilankelman.org/stopsigns/australia.jpg\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This image shows a bustling street scene in what appears to be a Chinatown area. The focal point is a red stop sign with white lettering, positioned on a metal pole. Behind the stop sign, there's a large red archway with Chinese characters, likely marking the entrance to a Chinatown district.\n",
            "\n",
            "The street is lined with various shops and businesses, including a store called \"Optus\" and another with a sign that says \"KUO\". There are also other businesses visible, though their names aren't clearly identifiable.\n",
            "\n",
            "A black SUV is driving down the street, and there are a few pedestrians visible in the background. The scene is set during the day, with sunlight illuminating the area.\n",
            "\n",
            "The architecture and signage strongly suggest this is a Chinatown district in a city, possibly in Australia given the \"Optus\" sign, which is an Australian telecommunications company. The combination of Chinese characters, the style of the buildings, and the presence of Chinese cultural elements like the archway and lion statues all point to this being a Chinatown area.<|im_end|>\n"
          ]
        }
      ]
    }
  ]
}